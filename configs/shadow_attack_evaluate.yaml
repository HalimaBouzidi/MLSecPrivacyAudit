attack:
  type: shadow # choices: [population, reference, shadow]
  privacy_game: privacy_loss_model # choices: [privacy_loss_model, avg_privacy_loss_training_algo, privacy_loss_sample]
  signal: loss # choices: [loss, gradient, logits, scaled_logits]
  hypo_test: 'linear_itp' # choices: [direct, linear_itp, logit_rescale, gaussian, min_linear_gaussian]
  split_size: 8000 # for shadow attack
  n_shadow_models: 5 # for shadow attack
  log_dir: '/home/hbouzidi/hbouzidi/MLSecPrivacyAudit/logs'
  test_name: 'arbitary_test'

data:
  dataset: CIFAR100 # choices: [MNIST, CIFAR10, CIFAR100, TINY-IMAGENET, IMAGENET]
  in_channels: 3
  num_classes: 100
  dataset_dir: /home/hbouzidi/hbouzidi/datasets/cifar-100
  batch_size: 64
  data_loader_workers_per_gpu: 4
  distributed: False
  augment: auto_augment_tf

train:
  model_name: searchable_resnet # choices: [searchable_alexnet, searchable_transformer, searchable_mobilenet, searchable_resnet]
  width_multi: 1.0
  depth_multi: 5
  epochs: 200
  optimizer: adam
  learning_rate: 0.001 
  weight_decay: 0.0001 

run: 
  seed: 1234 
  saved_models: ./saved_models